# -*- coding: utf-8 -*-
"""
Created on Thu Oct  3 03:24:13 2024

@author: olanr
"""


"""
retrieve_embeddings.py

This module handles the monitoring and retrieval of embeddings generated by OpenAI's API. It includes functionality to check the status of batch jobs, write the resulting embeddings to files, and manage asynchronous operations.

Classes:
    - MonitorAndRetrieveEmbeddings: A class to monitor batch jobs and retrieve embeddings.

Usage:
    Create an instance of `MonitorAndRetrieveEmbeddings` with an OpenAI client, then use its methods to monitor job statuses and write embeddings to output files.
"""


from openai_kit import OpenAI
from auxiliaries import Dict, List
from auxiliaries import make_directory
import asyncio
import os



class MonitorAndRetrieveEmbeddings:
    
    
    def __init__(self, openai_client: OpenAI):
        self.openai_client = openai_client
        
    
    async def _check_job_status(self, job_id: str, check_idx: int)->Dict:
    
        """
        Checks the status of a batch job until it completes.
    
        Args:
            openai_client (OpenAI): The OpenAI client instance.
            job_id (str): The ID of the batch job to check.
            check_idx (int): The current check iteration index.
    
        Returns:
            Dict: A dictionary containing the batch ID and output file ID upon completion.
        """
        
        while True:
            job = self.openai_client.batches.retrieve(job_id)
            if job.output_file_id:
                print(f"Job {job_id} complete. Output file ID: {job.output_file_id}")
                return {job_id: job.output_file_id}  # Return job_id and output file ID
    
            print(f"===Current status for Batch ID: {job_id}===")
            completed = job.request_counts.completed
            failed = job.request_counts.failed
            total = completed = job.request_counts.total
            print(f"Check Number: {check_idx}")
            print(f"Completion status: \n{completed = }\n{failed = }\n{total = }\n\n")
            
            await asyncio.sleep(60)  # Wait for 60 seconds before checking again
    
            
    
    async def monitor_multiple_jobs(self, job_ids: List):
    
        """
        Monitors multiple batch jobs concurrently.
    
        Args:
            openai_client (OpenAI): The OpenAI client instance.
            job_ids (List): A list of batch job IDs to monitor.
    
        Returns:
            List: A list of results from the monitored jobs.
        """
        
        print("\n===================== Monitoring Mulitple Batch Jobs =====================")
        tasks = [self._check_job_status(job_id, check_idx) for check_idx, job_id in enumerate(job_ids)]
        results = await asyncio.gather(*tasks)  # Wait for all tasks to complete
        return results  # Collect and return the results
    
    
    
    def write_enbeddings_to_file(self, output_file_ids: Dict, output_folder: str)->None:
    
        """
        Writes embeddings to files based on output file IDs.
    
        Args:
            output_file_ids (Dict): A dictionary mapping batch IDs to output file IDs.
            output_folder (str): The folder to save the output files.
        """
        
        print(f"\n\nWriting the embeddings to output folder {output_folder}")
        if not output_file_ids:
            print("Cannot write embeddings to file because there is no Output File ID")
            return
        print(f"Making the directory: {output_folder}")
        make_directory(output_folder)
        
        for idx, output_file_id_map in enumerate(output_file_ids):
            output_file_id = [val for val in output_file_id_map.values()][0]
            
            file_content = self.openai_client.files.content(output_file_id)
    
            output_filepath = os.path.join(output_folder, f"gpt_output_{idx}.jsonl")
            with open(output_filepath, "wb") as f:
                f.write(file_content.read())
            print(f"{output_filepath} file created and populated with embeddings")
    

    @staticmethod
    def run_async(func, *args):
        """
        Run an async function in a blocking way.

        Args:
            func: The asynchronous function to run.
            *args: Arguments to pass to the async function.

        Returns:
            The result of the asynchronous function execution.
        """
        
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(func(*args))
